{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "# functions\n",
    "from functions import *\n",
    "import time\n",
    "# ML\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LinearSVC, RandomForestClassifier, GBTClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.feature import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/06 15:11:04 WARN Utils: Your hostname, cuiyeshuaideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.31.122 instead (on interface en0)\n",
      "22/04/06 15:11:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/06 15:11:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setAppName(\"spark\").setMaster(\"local[*,20]\").set(\"spark.driver.memory\", \"10g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giao():\n",
    "    file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "    # (file_name, ProvDocument)\n",
    "    # (file_name, Graphic_encoding_of_ProvDocument)\n",
    "    #encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "    encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "    # (file_name, prov_types of nodes)\n",
    "    if forward:\n",
    "        types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "        # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    else:\n",
    "        types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # (file_name, prov_types occurence in the graph)\n",
    "    types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "    # All prov_types in this collection of graphs\n",
    "    all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "    # Number of distinct prov_types\n",
    "    types_count = len(all_types)\n",
    "    print(types_count)\n",
    "    # index_map for prov_types, prov_type -> index\n",
    "    index_map = {all_types[i]: i for i in range(types_count)}\n",
    "    # index -> prov_type\n",
    "    # Contruct feature vectors for each graph\n",
    "    sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "    feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "    df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "    scaler_model = scaler.fit(df_features)\n",
    "    df_features = scaler_model.transform(df_features)\n",
    "    # Change the labels\n",
    "    df_labels = spark.read.csv(label_csv, header=True)\n",
    "    df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "    df_labels = df_labels.filter(df_labels.label.isin(label_map.values()))\n",
    "    df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "    # Join the features and labels\n",
    "    df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "    # Oversample the training data\n",
    "    labels = [float(x) for x in label_map.values()]\n",
    "    count = {}\n",
    "    for x in labels:\n",
    "        count[x] = df.filter(df['label'] == x).count()\n",
    "    maxValue = max(count.values())\n",
    "    print(maxValue)\n",
    "    ratio = {}\n",
    "    for x in labels:\n",
    "        ratio[x] = maxValue/count[x]\n",
    "    dataframes = []\n",
    "    for x in labels:\n",
    "        if(count[x] == maxValue):\n",
    "            dataframes.append(df.filter(df['label'] == x))\n",
    "        else:\n",
    "            dataframes.append(df.filter(df['label'] == x).sample(withReplacement=True, fraction=ratio[x]))\n",
    "    train = dataframes[0]\n",
    "    for dataframe in dataframes[1:]:\n",
    "        train = train.union(dataframe)\n",
    "    print(ratio)\n",
    "    for x in labels:\n",
    "        print(train.filter(train['label'] == x).count())\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    # LinearSVC classifier\n",
    "    start = time.time()\n",
    "    svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "    pipeline = Pipeline(stages=[svc])\n",
    "    paramGrid = ParamGridBuilder().addGrid(svc.regParam, [0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 200]).build()\n",
    "    # train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "    crossval = CrossValidator(\n",
    "        estimator=pipeline, \n",
    "        estimatorParamMaps=paramGrid, \n",
    "        evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "        numFolds=10,\n",
    "        collectSubModels=True)\n",
    "    cvModel = crossval.fit(train)\n",
    "\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    result.append(max(cvModel.avgMetrics))\n",
    "    result.append(end-start)\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "    pipeline = Pipeline(stages=[rf])\n",
    "    paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [4,5,6]).build()\n",
    "    # train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "    crossval = CrossValidator(\n",
    "        estimator=pipeline, \n",
    "        estimatorParamMaps=paramGrid, \n",
    "        evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "        numFolds=10,\n",
    "        collectSubModels=True)\n",
    "    cvModel = crossval.fit(train)\n",
    "    end = time.time()\n",
    "    result.append(max(cvModel.avgMetrics))\n",
    "    result.append(end-start)\n",
    "    print(end-start)\n",
    "    start = time.time()\n",
    "    gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "    pipeline = Pipeline(stages=[gbt])\n",
    "    paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "    # train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "    crossval = CrossValidator(\n",
    "        estimator=pipeline, \n",
    "        estimatorParamMaps=paramGrid, \n",
    "        evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "        numFolds=10,\n",
    "        collectSubModels=True)\n",
    "    cvModel = crossval.fit(train)\n",
    "    end = time.time()\n",
    "    result.append(max(cvModel.avgMetrics))\n",
    "    result.append(end-start)\n",
    "    print(end-start)\n",
    "    start = time.time()\n",
    "    lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "    pipeline = Pipeline(stages=[lr])\n",
    "    paramGrid = ParamGridBuilder().addGrid(lr.maxIter, [5,10]).addGrid(lr.regParam, [0.2,0.3,0.4]).addGrid(lr.elasticNetParam, [0.6,0.7,0.8]).build()\n",
    "    # train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "    crossval = CrossValidator(\n",
    "        estimator=pipeline,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"),\n",
    "        numFolds=10,\n",
    "        collectSubModels=True)\n",
    "    cvModel = crossval.fit(train)\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    result.append(max(cvModel.avgMetrics))\n",
    "    result.append(end-start)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "ParseException",
     "evalue": "\nno viable alternative at input 'not in label_map'(line 1, pos 24)\n\n== SQL ==\ndf_labels[label] not in label_map.values()\n------------------------^^^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/cuiyeshuai/Documents/UG modules/submission/evaluation.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cuiyeshuai/Documents/UG%20modules/submission/evaluation.ipynb#ch0000003?line=1'>2</a>\u001b[0m specific_types_node \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cuiyeshuai/Documents/UG%20modules/submission/evaluation.ipynb#ch0000003?line=2'>3</a>\u001b[0m level \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cuiyeshuai/Documents/UG%20modules/submission/evaluation.ipynb#ch0000003?line=3'>4</a>\u001b[0m giao()\n",
      "\u001b[1;32m/Users/cuiyeshuai/Documents/UG modules/submission/evaluation.ipynb Cell 3'\u001b[0m in \u001b[0;36mgiao\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cuiyeshuai/Documents/UG%20modules/submission/evaluation.ipynb#ch0000002?line=31'>32</a>\u001b[0m df_labels \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39mcsv(label_csv, header\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cuiyeshuai/Documents/UG%20modules/submission/evaluation.ipynb#ch0000002?line=32'>33</a>\u001b[0m df_labels \u001b[39m=\u001b[39m df_labels\u001b[39m.\u001b[39mreplace(label_map, subset\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cuiyeshuai/Documents/UG%20modules/submission/evaluation.ipynb#ch0000002?line=33'>34</a>\u001b[0m df_labels \u001b[39m=\u001b[39m df_labels\u001b[39m.\u001b[39;49mfilter(\u001b[39m\"\u001b[39;49m\u001b[39mdf_labels[label] not in label_map.values()\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cuiyeshuai/Documents/UG%20modules/submission/evaluation.ipynb#ch0000002?line=34'>35</a>\u001b[0m df_labels \u001b[39m=\u001b[39m df_labels\u001b[39m.\u001b[39mwithColumn(\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m, df_labels[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mcast(DoubleType()))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cuiyeshuai/Documents/UG%20modules/submission/evaluation.ipynb#ch0000002?line=35'>36</a>\u001b[0m \u001b[39m# Join the features and labels\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyspark/sql/dataframe.py:1731\u001b[0m, in \u001b[0;36mDataFrame.filter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/dataframe.py?line=1705'>1706</a>\u001b[0m \u001b[39m\"\"\"Filters rows using the given condition.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/dataframe.py?line=1706'>1707</a>\u001b[0m \n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/dataframe.py?line=1707'>1708</a>\u001b[0m \u001b[39m:func:`where` is an alias for :func:`filter`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/dataframe.py?line=1727'>1728</a>\u001b[0m \u001b[39m[Row(age=2, name='Alice')]\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/dataframe.py?line=1728'>1729</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/dataframe.py?line=1729'>1730</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(condition, \u001b[39mstr\u001b[39m):\n\u001b[0;32m-> <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/dataframe.py?line=1730'>1731</a>\u001b[0m     jdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mfilter(condition)\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/dataframe.py?line=1731'>1732</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(condition, Column):\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/dataframe.py?line=1732'>1733</a>\u001b[0m     jdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jdf\u001b[39m.\u001b[39mfilter(condition\u001b[39m.\u001b[39m_jc)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/py4j/java_gateway.py:1309\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/py4j/java_gateway.py?line=1302'>1303</a>\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/py4j/java_gateway.py?line=1303'>1304</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/py4j/java_gateway.py?line=1304'>1305</a>\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/py4j/java_gateway.py?line=1305'>1306</a>\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/py4j/java_gateway.py?line=1307'>1308</a>\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/py4j/java_gateway.py?line=1308'>1309</a>\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/py4j/java_gateway.py?line=1309'>1310</a>\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/py4j/java_gateway.py?line=1311'>1312</a>\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/py4j/java_gateway.py?line=1312'>1313</a>\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/utils.py?line=112'>113</a>\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/utils.py?line=113'>114</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/utils.py?line=114'>115</a>\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/utils.py?line=115'>116</a>\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/utils.py?line=116'>117</a>\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/utils.py?line=117'>118</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/sql/utils.py?line=118'>119</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mParseException\u001b[0m: \nno viable alternative at input 'not in label_map'(line 1, pos 24)\n\n== SQL ==\ndf_labels[label] not in label_map.values()\n------------------------^^^\n"
     ]
    }
   ],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 4\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 4\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 4\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 4\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 5\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 5\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 5\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 5\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 6\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 6\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 6\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 6\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 2\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 2\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 2\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 2\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 1\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 1\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 1\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 1\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 0\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 0\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 0\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 0\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/PG-T/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/PG-T/graphs.csv\"\n",
    "label_map = {\n",
    "    \"Valor\": \"0.0\",\n",
    "    \"Instinct\": \"1.0\",\n",
    "    \"Mystic\": \"2.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 1\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 1\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 1\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 1\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 2\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 2\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 2\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 2\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 3\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 3\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 3\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 3\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 4\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 4\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 4\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 4\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 5\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 5\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 5\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 5\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 6\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 6\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 6\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 6\n",
    "giao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 4\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 4\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 5\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 5\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "print(types_count)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 5\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 5\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 6\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 6\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 6\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 6\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 7\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = True\n",
    "specific_types_node = False\n",
    "level = 7\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = False\n",
    "specific_types_node = True\n",
    "level = 7\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = False\n",
    "specific_types_node = False\n",
    "level = 7\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")\n",
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)\n",
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))\n",
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))\n",
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))\n",
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))\n",
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}\n",
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)\n",
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))\n",
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")\n",
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)\n",
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())\n",
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
