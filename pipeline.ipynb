{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "# functions\n",
    "from functions import *\n",
    "# ML\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LinearSVC, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.feature import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_folder = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/*.json\"\n",
    "label_csv = \"/Users/cuiyeshuai/Documents/UG modules/Individual Project/provenance-kernel-evaluation-master/datasets/CM-Buildings/graphs.csv\"\n",
    "specific_types_edge = True\n",
    "specific_types_node = True\n",
    "level = 4\n",
    "iri = False\n",
    "forward = False\n",
    "qualified_names = {\n",
    "    \"xsd:QName\",\n",
    "    \"prov:QUALIFIED_NAME\"\n",
    "}\n",
    "label_map = {\n",
    "    \"Trusted\": \"1.0\",\n",
    "    \"Uncertain\": \"0.0\"\n",
    "}\n",
    "# label_map = {\n",
    "#     \"Valor\": 0.0,\n",
    "#     \"Instinct\": 1.0,\n",
    "#     \"Mystic\": 2.0\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/04 20:34:28 WARN Utils: Your hostname, cuiyeshuaideMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.31.122 instead (on interface en0)\n",
      "22/04/04 20:34:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/04 20:34:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/04/04 20:34:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf().setAppName(\"spark\").setMaster(\"local[*]\").set(\"spark.driver.memory\", \"15g\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "# spark.sparkContext.addPyFile(\"functions.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into rdd (file_path, json_data(string))\n",
    "file_and_path_rdd = spark.sparkContext.wholeTextFiles(json_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (file_name, ProvDocument)\n",
    "document_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], (ProvDocument.deserialize(content=x[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (file_name, Graphic_encoding_of_ProvDocument)\n",
    "#encoding_rdd = document_rdd.map(lambda x: (x[0], document_to_encoding(x[1],iri,forward)))\n",
    "encoding_rdd = file_and_path_rdd.map(lambda x: (x[0].split(\"/\")[-1], json_to_encoding(x[1],iri,forward,qualified_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (file_name, prov_types of nodes)\n",
    "if forward:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate(x[1], level, specific_types_node, specific_types_edge)))\n",
    "    # types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_mixed(x[1], level, specific_types_node, specific_types_edge)))\n",
    "else:\n",
    "    types_rdd = encoding_rdd.map(lambda x: (x[0], type_generate_R(x[1], level, specific_types_node, specific_types_edge)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (file_name, prov_types occurence in the graph)\n",
    "types_count_rdd = types_rdd.map(lambda x: (x[0], count_prov_types(level,x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n",
      "/Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/python/lib/pyspark.zip/pyspark/shuffle.py:60: UserWarning: Please install psutil to have better support with spilling\n",
      "  warnings.warn(\"Please install psutil to have better \"\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# All prov_types in this collection of graphs\n",
    "all_types = types_count_rdd.flatMap(lambda x: x[1].keys()).distinct().collect()\n",
    "# Number of distinct prov_types\n",
    "types_count = len(all_types)\n",
    "# index_map for prov_types, prov_type -> index\n",
    "index_map = {all_types[i]: i for i in range(types_count)}\n",
    "# index -> prov_type\n",
    "reverse_index_map = {i: all_types[i] for i in range(types_count)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contruct feature vectors for each graph\n",
    "sparse_matrix_rdd = types_count_rdd.map(lambda x: (x[0], sparse_matrix(x[1], types_count, index_map)))\n",
    "feature_vector_rdd = sparse_matrix_rdd.map(lambda x: (x[0],Vectors.dense(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe from rdd\n",
    "df_features = spark.createDataFrame(feature_vector_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scaler_model = scaler.fit(df_features)\n",
    "df_features = scaler_model.transform(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the labels\n",
    "df_labels = spark.read.csv(label_csv, header=True)\n",
    "df_labels = df_labels.replace(label_map, subset=[\"label\"])\n",
    "df_labels = df_labels.withColumn(\"label\", df_labels[\"label\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the features and labels\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.scaledFeatures, df_labels.label).withColumnRenamed(\"scaledFeatures\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing\n",
    "train, test = df.randomSplit([0.8, 0.2], seed = 123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 1.0, 0.0: 6.405063291139241}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------                                        \n",
      "Exception happened during processing of request from ('127.0.0.1', 61435)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"/Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/Users/cuiyeshuai/Library/Python/3.8/lib/python/site-packages/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Oversample the data\n",
    "labels = [float(x) for x in label_map.values()]\n",
    "count = {}\n",
    "for x in labels:\n",
    "    count[x] = train.filter(train['label'] == x).count()\n",
    "maxValue = max(count.values())\n",
    "ratio = {}\n",
    "for x in labels:\n",
    "    ratio[x] = maxValue/count[x]\n",
    "dataframes = []\n",
    "for x in labels:\n",
    "    if(count[x] == maxValue):\n",
    "        dataframes.append(train.filter(train['label'] == x))\n",
    "    else:\n",
    "        dataframes.append(train.filter(train['label'] == x).sample(withReplacement=True, fraction=ratio[x], seed=123456))\n",
    "train = dataframes[0]\n",
    "for dataframe in dataframes[1:]:\n",
    "    train = train.union(dataframe)\n",
    "print(ratio)\n",
    "for x in labels:\n",
    "    print(train.filter(train['label'] == x).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearSVC classifier\n",
    "svc = LinearSVC(maxIter = 100, threshold=0.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[svc])\n",
    "paramGrid = ParamGridBuilder().addGrid(svc.regParam, [1, 0.1, 0.01,0.001,0.0001,0.00001]).addGrid(svc.maxIter, [100, 500]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = cvModel.bestModel.stages[0].coefficients\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = LinearSVC()\n",
    "# svc_model = svc.fit(train)\n",
    "# res_test = svc_model.transform(test)\n",
    "\n",
    "# # convert to dataframe and compute the metrics\n",
    "# preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "# metrics = MulticlassMetrics(preds_and_labels)\n",
    "# print(metrics.accuracy)\n",
    "# print(metrics.confusionMatrix().toArray())\n",
    "# svc_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important_features(coef.toArray(), reverse_index_map, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "paramGrid = ParamGridBuilder().addGrid(rf.numTrees, [5,10,20,30]).addGrid(rf.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "gbt_model = gbt.fit(train)\n",
    "res_test = gbt_model.transform(test)\n",
    "\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxIter, [5,10]).addGrid(gbt.maxDepth, [3,4,5,6]).build()\n",
    "# train the model and select the best model using \"metricName\"(hyperparameter tuning)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline, \n",
    "    estimatorParamMaps=paramGrid, \n",
    "    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"), \n",
    "    numFolds=10,\n",
    "    collectSubModels=True)\n",
    "cvModel = crossval.fit(train)\n",
    "\n",
    "# predict the labels of test data\n",
    "res_test = cvModel.bestModel.transform(test)\n",
    "\n",
    "# convert to dataframe and compute the metrics\n",
    "preds_and_labels = res_test.select(\"prediction\", \"label\").rdd.map(lambda x: (x[0], x[1]))\n",
    "metrics = MulticlassMetrics(preds_and_labels)\n",
    "print(metrics.accuracy)\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(list(zip(cvModel.avgMetrics, paramGrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = spark.createDataFrame(sparse_matrix_rdd).withColumnRenamed(\"_1\", \"file\").withColumnRenamed(\"_2\", \"features\")\n",
    "df = df_features.join(df_labels, df_features.file == df_labels.graph_file).select(df_features.features, df_labels.label)\n",
    "df_list = df.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = train.collect()\n",
    "test_list = test.collect()\n",
    "X_train = [x[0] for x in train_list]\n",
    "y_train = [x[1] for x in train_list]\n",
    "X_test = [x[0] for x in test_list]\n",
    "y_test = [x[1] for x in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# X = np.array([x[0] for x in df_list])\n",
    "# y = np.array([x[1] for x in df_list])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "    SVC(kernel=\"linear\"))\n",
    "clf.fit(X_train, y_train)\n",
    "(clf.predict(X_test), y_test)\n",
    "print(confusion_matrix(clf.predict(X_test), y_test))\n",
    "print(accuracy_score(clf.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# X = np.array([x[0] for x in df_list])\n",
    "# y = np.array([x[1] for x in df_list])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "    LinearSVC())\n",
    "clf.fit(X_train, y_train)\n",
    "(clf.predict(X_test), y_test)\n",
    "print(confusion_matrix(clf.predict(X_test), y_test))\n",
    "print(accuracy_score(clf.predict(X_test), y_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
